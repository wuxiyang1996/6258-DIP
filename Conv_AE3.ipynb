{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conv_AE3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xwu391/6258-DIP/blob/master/Conv_AE3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiaSmqRbhJ4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from  torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from  torchvision import datasets, transforms\n",
        "from  sklearn.decomposition.pca import PCA\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "817A8Ja9yFgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XugEj8sBjoAD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "f6a425d8-d744-4d0e-de08-1d00d39eea4c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRrf9b11nkdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Conv_AE(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Conv_AE, self).__init__()\n",
        "    self.Encoder_Net = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "        nn.LeakyReLU(inplace=True),\n",
        "\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "        nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "        nn.LeakyReLU(inplace=True),\n",
        "\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "        nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "        nn.LeakyReLU(inplace=True),\n",
        "\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "        nn.Conv2d(in_channels=32, out_channels=4, kernel_size=3, stride=1, padding=1),\n",
        "        nn.LeakyReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "    self.Decoder_Net = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels=4, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "        nn.LeakyReLU(inplace=True),\n",
        "        nn.BatchNorm2d(32),\n",
        "\n",
        "        nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=2, stride=2),\n",
        "        nn.LeakyReLU(inplace=True),\n",
        "        nn.BatchNorm2d(32),\n",
        "\n",
        "        nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=2, stride=2),\n",
        "        nn.LeakyReLU(inplace=True),\n",
        "        nn.BatchNorm2d(32),\n",
        "\n",
        "        nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=2, stride=2),\n",
        "        nn.LeakyReLU(inplace=True),\n",
        "        nn.BatchNorm2d(32),\n",
        "\n",
        "        nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "        nn.LeakyReLU(inplace=True),\n",
        "        nn.BatchNorm2d(32),\n",
        "\n",
        "        nn.Conv2d(in_channels=32, out_channels=1, kernel_size=1, stride=1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def Encoder(self, input_img):\n",
        "    x = self.Encoder_Net(input_img)\n",
        "  #  x = self.fc1(x)\n",
        "    return x\n",
        "\n",
        "  def Decoder(self, input_img):\n",
        "  #  x = self.fc2(input_img)\n",
        "    x = self.Decoder_Net(input_img)\n",
        "    return x\n",
        "    \n",
        "  def forward(self, input_img):\n",
        "    code = self.Encoder(input_img)\n",
        "    recover = self.Decoder(code)\n",
        "    return recover, code\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDVi95tO4VuG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "6fe45fce-5af6-4275-f14f-f79a5fee95b9"
      },
      "source": [
        "Pre_transfrom = transforms.Compose([\n",
        "        transforms.Resize((128,128)),\n",
        "        transforms.Grayscale(),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data/', train=True, transform=Pre_transfrom, download=True)\n",
        "#test_dataset = datasets.MNIST(root='./data/', train=False, transform=Pre_transfrom)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=200, num_workers=20, drop_last=True)\n",
        "\n",
        "conv_AE = Conv_AE().cuda()\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = optim.SGD(conv_AE.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "\n",
        "for epoch in range(50):\n",
        "  print(\"Epoch %d\" % epoch)\n",
        "\n",
        "  for i, (images, _) in enumerate(train_loader):\n",
        "    images = Variable(images).cuda()\n",
        "    recover, _ = conv_AE(images)\n",
        "        \n",
        "    optimizer.zero_grad()\n",
        "    loss = loss_function(recover, images)\n",
        "    loss.backward()\n",
        "    optimizer.step()        \n",
        "        \n",
        "  print(\"Loss = %.5f\" % loss.item()) \n",
        "  if (epoch%20==0):\n",
        "    torch.save(conv_AE, 'CAE3-3.pkl')\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Loss = 0.05177\n",
            "Epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-92b950bdc513>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mrecover\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_AE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M9rAECGWCpnP",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "conv_AE = torch.load('CAE3-3.pkl')\n",
        "Pre_transfrom = transforms.Compose([\n",
        "        transforms.Resize((128,128)),\n",
        "        transforms.Grayscale(),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "test_dataset = datasets.ImageFolder(root='test/', transform=Pre_transfrom)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False, batch_size=1, num_workers=1, drop_last=True)\n",
        "\n",
        "for i, (images, _) in enumerate(test_loader):\n",
        "    images = Variable(images).cuda()\n",
        "    recover, code = conv_AE(images)\n",
        "    torchvision.utils.save_image(recover.data, 'Conv1' + str(i) + '.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im4dbQdAJYyJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "f9b11b91-61f2-4042-ff18-d2db72402396"
      },
      "source": [
        "pip install dippykit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dippykit\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/2a/20a50295edc4b6de88244261b671eb3522e39020c177e42cbc5d0f5167a7/dippykit-2.0.3.tar.gz (52kB)\n",
            "\r\u001b[K     |██████▎                         | 10kB 13.3MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 20kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 30kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 40kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from dippykit) (3.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from dippykit) (1.17.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from dippykit) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from dippykit) (4.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from dippykit) (1.3.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from dippykit) (0.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->dippykit) (2.6.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->dippykit) (2.4.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->dippykit) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->dippykit) (1.1.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->dippykit) (0.46)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->dippykit) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->dippykit) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->dippykit) (2.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->dippykit) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->dippykit) (42.0.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->dippykit) (4.4.1)\n",
            "Building wheels for collected packages: dippykit\n",
            "  Building wheel for dippykit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dippykit: filename=dippykit-2.0.3-cp36-none-any.whl size=58952 sha256=6b24f45fb4e5018e5da058812a067bb30d04f0b3858a89b7cd6786fb9bc90cb7\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/42/9c/a692a4fe24e12db06f80e6e86dcc79cfe784ad832e9a5e96ff\n",
            "Successfully built dippykit\n",
            "Installing collected packages: dippykit\n",
            "Successfully installed dippykit-2.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7F3jbGZGPUf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d5fdb674-485d-4e40-9169-c0e51c133aa1"
      },
      "source": [
        "import dippykit as dip\n",
        "code1 = torch.mul(code, 1000000).reshape(16*16*4)\n",
        "code1 = torch.round(code1).cpu().detach().numpy()\n",
        "code2 = np.zeros(256*4, dtype=int);\n",
        "for i in range(256*4):\n",
        "  code2[i] = int(code1[i])\n",
        "\n",
        "img_en, stream_length, _, _ = dip.huffman_encode(code2)\n",
        "print(stream_length)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9397\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}